---
title: 'Fase 2: Clustering'
author: "Irving, Chuy"
date: "2025-02-10"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(dplyr)
library(kableExtra)
library(tidyr)
library(ggplot2)

library(lubridate)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
```

```{r, include=FALSE}
movies <- read.csv("./movies.csv")

```

## 1.1 Seleccion de columnas
```{r echo=FALSE}
columns <- c("id", "popularity", "budget", "revenue", "runtime", "genresAmount", "productionCountriesAmount", "releaseDate", "voteCount", "voteAvg", "actorsPopularity", "actorsAmount", "castWomenAmount", "castMenAmount")

selected_movies_clustr <- movies[,columns]

selected_movies_clustr

```

# Conversion de columnas no numericas
```{r echo=FALSE}
pupoular_sum <- selected_movies_clustr %>%
  separate_rows( actorsPopularity, sep = "|") %>%
  mutate(actorsPopularity = as.numeric(actorsPopularity)) %>%
  group_by(id) %>%
  summarise(totalActorPopularity = sum(actorsPopularity, na.rm = TRUE))

pupoular_sum

df_final <- selected_movies_clustr %>%
  left_join(pupoular_sum, by = "id")

df_final <- df_final %>% select(-actorsPopularity)

df_final$releaseDate <- as.Date(df_final$releaseDate, format = "%d/%m/%Y")

# df_final$year <- year(df_final$releaseDate)
# df_final$month <- month(df_final$releaseDate)
# df_final$day <- day(df_final$releaseDate)

df_final <- df_final %>% select(-releaseDate)
df_ids <- selected_movies_clustr %>% select(id)

df_final <- df_final %>% select(-id)


# columnas que se deben pasar a char

# data filtering
df_final <- df_final %>%
  mutate(
    castWomenAmount = ifelse(grepl("^[0-9]+$", castWomenAmount), as.integer(castWomenAmount), NA),
    castMenAmount = ifelse(grepl("^[0-9]+$", castMenAmount), as.integer(castMenAmount), NA)
  )

# Replace remaining NA values with 0
df_final$castWomenAmount[is.na(df_final$castWomenAmount)] <- 0
df_final$castMenAmount[is.na(df_final$castMenAmount)] <- 0

# Aqui se puede probar con tamanios distintos de muestras. 
# df_final <- df_final[sample(nrow(df_final), 100), ]

z_scores <- scale(df_final) 
outliers <- apply(abs(z_scores) > 3, 2, sum)  # Count extreme values
print(outliers)

df_final <- df_final %>%
  mutate(across(where(is.numeric), ~ ifelse(. > quantile(., 0.99), quantile(., 0.99), .)))

df_final

```
## Escalado de los datos
Es importante escalar los datos antes de realizar agrupamientos cuando se utilizan tecnicas de aprendizaje no supervisado como lo es el clustering. Dentro del data set tenemos unicamente vlores numericos, entonces podemos escalarlos para que el agrupamiento funcione mejor.

```{r echo=FALSE}
# Comentado de momento, escalar los datos impide que se vea el grafico de codo bien
# df_final <- as.data.frame(scale(df_final))  # Convert back to data.frame
# colSums(is.na(df_final))
```

## Estadistico de Hopkins 

Es importante saber si es plausible hacer un agrupamiento de datos con la data frame que tenemos. Para ello hemos decidido utilizar el estadistico de hopkins
```{r echo=FALSE}
set.seed(123)
hopkins(df_final)
```
Como se puede observar el data set tiene bastante potencial para hacer grupos.Es raro que los datos esten tan bien relacionados (el valor fue de 1 en algunas pruebas) pero si probamos revolviendo los datos de igual manera se obtiene un numero cercano a 1. Lo cual implica que los datos pueden agruparse bastante bien

```{r echo=FALSE}
set.seed(123)
df_shuffled <- df_final[sample(nrow(df_final)), ]
hopkins(df_shuffled)
```
Con esto practicamente nos aseguramos de que nuestros datos pueden ser agrupados exitosamente. Antes de proceder con la definicion de grupos, haremos un un VAT (Evaluacion visual de tendencia por sus siglas en ingles). Este metodo grafico ayudara a corroborar el estdistico de hopkins de manera visual. Si se ve un patron visible y no aleatorio eso quiere decir que nuevamente los datos son adecuados para agruparse. Nota: Tomamos una muestra aleatorio del data set con el fin de ahorrar recursos computacionales. EL dataset tiene 10000 lineas, por lo que tomar el data set completo tomaria demasiado tiempo

```{r echo=FALSE}
set.seed(123)
sampled_df <- df_final[sample(nrow(df_final), 1000), ]  # muestra
dist_matrix <- dist(sampled_df)
fviz_dist(dist_matrix, show_labels = FALSE)
```

Puede observarse un patron visible, por lo que podemos decir que en efecto la data que tenemos puede ser agrupada. Puede que se vea un poco opaco, pero esto ocurre debido a que realmente no estamos usando la totalidad de los datos. Ahora que ya hemos confirmado que podemos agrupar, hay que definir la cantidad de grupos que deseamos hacer mediante el clustering. El numero de grupos lo obtendremos mediante el grafico de codo.

## Grafico de codo
``` {r echo=FALSE}
wss=0

wss <- sapply(1:8, function(i) sum(kmeans(df_final, centers = i)$withinss))

# Graficando el codo
plot(1:8, wss, type = "b", pch = 19, col = "blue", 
     xlab = "Numero de Clusters", ylab = "Suma de cuadrados dentro de los grupos",
     main = "Metodo del Codo")

#sil_width <- sapply(2:8, function(i) {
#  km <- kmeans(df_final, centers = i)
#  ss <- silhouette(km$cluster, dist(df_final))
#  mean(ss[, 3])
#})

#plot(2:8, sil_width, type = "b", pch = 19, col = "blue", 
#     xlab = "Número de Clusters", ylab = "Ancho de Silueta",
#     main = "Método de la Silueta")
```

Como se puede observar el grafico de codo indica que la cantidad ideal de grupos es 3 o 4. Justo en esa parte de la grafica es donde se ve la forma que indica la cantidad de grupos apropiados para realizar el clustering. 

## Agrupamiento

Ahora que ya conocemos el numero de grupos es necesario agrupar los datos utilizando algoritmos. Se usaran y evaluaron 2 principalmente "Kmeans" y "Clustering jerarquico" con la cantidad de 3 grupos.


### Kmeans
```{r echo=FALSE}
set.seed(123) 
km <- kmeans(df_final,3,iter.max = 1000)

df_final$grupo <- km$cluster

km

fviz_cluster(km, data = df_final, ellipse.type = "norm")

km$withinss
```

### Clustering jerarquico
```{r echo=FALSE}

df_dist <- dist(df_final)
hc<-hclust(df_dist, method = "ward.D2") #Genera el clustering jerarquico
plot(hc, cex=0.5, axes=FALSE) #Genera el dendograma
rect.hclust(hc,k=3)

```

```{r echo=FALSE}
groups<-cutree(hc,k=3) 
df_final$gruposHC<-groups

table(df_final$gruposHC) # tamanio de los grupos
by(df_final, df_final[,"gruposHC"], colMeans)

```

## Evaluacion con metodo de silhueta de K-means
```{r echo=FALSE}

silkm <- silhouette(km$cluster,df_dist)

mean(silkm[,3])

fviz_silhouette(silkm, main = "Silhueta para K-Medias", color = "cluster")

```

## Evaluacion con metodo de silhueta para Clustering Jerarquico
```{r echo=FALSE}

silhc<-silhouette(groups,df_dist)
mean(silhc[,3]) #

fviz_silhouette(silhc, main = "Silhueta para clustering jerarquico", color = "cluster")

```

Al final se puede observar que el algoritmo de Kmedias fue ligeramente mejor que el clustering jerarquico. Por lo que se utilizaran los grupos creados mediante dicho algoritmo. Aunque la metrica de la silhueta muestra un valor que no es tan cercano a 1, de igual manera los grupos son evidentes de manera grafica. Ahora se pueden analizar los grupos

```{r echo=FALSE}

df_final <- cbind(df_ids, df_final)
df_final <- df_final %>%
  left_join(movies %>% select(id, genres, productionCompany, productionCountry, productionCompanyCountry, director, actors, originalLanguage), by = "id")

```

# Analisis de las variables numericas
```{r echo=FALSE}

df_final %>%
  group_by(grupo) %>%
  summarise(across(where(is.numeric), list(media = mean, mediana = median, sd = sd), na.rm = TRUE))

df_final %>%
  filter(grupo == 1) %>%
  pivot_longer(cols = c(budget, revenue, runtime, genresAmount, voteCount, voteAvg, actorsAmount, totalActorPopularity), 
               names_to = "variable", values_to = "valor") %>%
  ggplot(aes(x = valor, fill = as.factor(grupo))) +
  geom_histogram(alpha = 0.6, bins = 30, position = "identity") +
  facet_wrap(~ variable, scales = "free") +
  labs(title = "Distribución de Variables Numéricas para Grupo 1", x = "Valor", y = "Frecuencia") +
  theme_minimal()

# Histograma para los demás grupos
df_final %>%
  filter(grupo != 1) %>%
  pivot_longer(cols = c(budget, revenue, runtime, genresAmount, voteCount, voteAvg, actorsAmount, totalActorPopularity), 
               names_to = "variable", values_to = "valor") %>%
  ggplot(aes(x = valor, fill = as.factor(grupo))) +
  geom_histogram(alpha = 0.6, bins = 30, position = "identity") +
  facet_wrap(~ variable, scales = "free") +
  labs(title = "Distribución de Variables Numéricas para Otros Grupos", x = "Valor", y = "Frecuencia") +
  theme_minimal()

df_promedios <- df_final %>%
  group_by(grupo) %>%
  summarise(across(c(budget, revenue, runtime, genresAmount, voteCount, voteAvg, actorsAmount, totalActorPopularity), 
                   mean, na.rm = TRUE), .groups = "drop") %>%
  pivot_longer(cols = -grupo, names_to = "variable", values_to = "promedio")

# Variables con valores muy grandes
df_promedios_grandes <- df_promedios %>%
  filter(variable %in% c("budget", "revenue"))

ggplot(df_promedios_grandes, aes(x = as.factor(grupo), y = promedio, fill = as.factor(grupo))) +
  geom_col(position = "dodge") +
  facet_wrap(~ variable, scales = "free") +
  labs(title = "Promedio de Variables con Valores Grandes por Grupo", x = "Grupo", y = "Promedio") +
  theme_minimal()

# Variables con valores más pequeños
df_promedios_pequenos <- df_promedios %>%
  filter(variable %in% c("runtime", "genresAmount", "voteCount", "voteAvg", "actorsAmount", "totalActorPopularity"))

ggplot(df_promedios_pequenos, aes(x = as.factor(grupo), y = promedio, fill = as.factor(grupo))) +
  geom_col(position = "dodge") +
  facet_wrap(~ variable, scales = "free") +
  labs(title = "Promedio de Variables con Valores Pequeños por Grupo", x = "Grupo", y = "Promedio") +
  theme_minimal()



```

```{r echo=FALSE}

ggplot(df_final, aes(x = as.factor(grupo), y = budget)) +
  geom_boxplot() +
  labs(title = "Distribucion del Presupuesto por Grupo", x = "Grupo", y = "Presupuesto")

```

# Analisis de frecuencia con variables categoricas
```{r  echo=FALSE}
df_final %>%
  separate_rows(genres, sep = "\\|") %>%
  count(grupo, genres) %>%
  ggplot(aes(x = genres, y = n, fill = as.factor(grupo))) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(title = "Frecuencia de Géneros por Grupo", x = "Genero", y = "Frecuencia")

df_final <- df_final %>%
  mutate(across(where(is.character), ~ iconv(.x, from = "latin1", to = "UTF-8")))

df_final %>%
  separate_rows(productionCompany, sep = "\\|") %>%
  count(grupo, productionCompany) %>%
  group_by(grupo) %>%
  slice_max(n, n = 10) %>%  # Filtrar los 10 más frecuentes de cada grupo
  ungroup() %>%
  ggplot(aes(x = reorder(productionCompany, n), y = n, fill = as.factor(grupo))) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(title = "Top 10 Production Companies por Grupo", x = "Production Company", y = "Frecuencia") +
  theme_minimal()

df_final %>%
  separate_rows(productionCountry, sep = "\\|") %>%
  count(grupo, productionCountry) %>%
  group_by(grupo) %>%
  slice_max(n, n = 10) %>%  # Filtrar los 10 países más frecuentes por grupo
  ungroup() %>%
  ggplot(aes(x = reorder(productionCountry, n), y = n, fill = as.factor(grupo))) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(title = "Top 10 Production Countries por Grupo", x = "País", y = "Frecuencia") +
  theme_minimal()

df_final %>%
  separate_rows(director, sep = "\\|") %>%
  count(grupo, director) %>%
  group_by(grupo) %>%
  slice_max(n, n = 10) %>%  # Filtrar los 10 países más frecuentes por grupo
  ungroup() %>%
  ggplot(aes(x = reorder(director, n), y = n, fill = as.factor(grupo))) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(title = "Top 10 Directores por Grupo", x = "Director", y = "Frecuencia") +
  theme_minimal()

```

# Conclusiones 

Luego de ver los resultados del agrupamiento tenemos 2 grupos que llaman la atención principalmente, el grupo 1 y el grupo 2. Analizando primero el grupo 2 nos podemos dar cuenta que es el grupo que tiene más datos de todos. Este es un cluster bastante grande y que tiene una gran variedad de películas. Este es particularmente para útil ver cuáles son los datos más comunes y populares dentro del set de datos en general. En este se pueden ver varios datos interesantes como los géneros de películas más comunes, por ejemplo, Drama, acción, thriller, comedia y horrar, son de los datos que más se repiten en el grupo 1. Osea que en general son los géneros de película más producidos. Además de esto podemos ver a las productoras, siendo las más recurrentes Warner Bros y Universal. Otra cosa es que en general casi todas las películas fueron producidas en algún punto en Estados unidos. Luego se puede ver que hay Directores que han participado en una cantidad enorme de proyectos en comparación a los demás. Siendo Sam Liu el mayor participe en la dirección de películas, seguido de Kunihiko Yuyama y Woody Allen.  

Pero es importante mencionar algo, que sea el cluster de películas más grande no quiere decir que sea el más exitoso. La otra parte interesante de este análisis se encuentra en el grupo 1. Como se pudo observar en las gráficas, el grupo 4 tiene menor representación y frecuencia en casi todas las ocasiones, pero esto no es algo malo. Si observamos la gráfica de valores promedio por grupo, podemos ver que el budget y revenue de las películas del grupo 2 no es muy alto en comparación a los demás grupos. Las películas del grupo 2, son de bajo presupuesto y por eso es que son las más comunes dentro de todos. Mientras que las películas del grupo 1, son los que fueron agrupados por ser más costosos, pero con mucho más ganancia en retorno.  Las películas con la mayor cantidad de budget por lo general tienen mayor popularidad en los actores, mejor nota promedio y son películas más largas. Y finalmente una relación bastante interesante que encontramos es la relación del director con las películas. Al ver el top 10 directores recurrentes en las películas (por grupo) podemos destacar los nombres de muchos directores de cine famosos que han hecho grandes éxitos. Directores como Steven Spilberg, Peter Jackson, Michael Bay, George Lucas, Christopher Nolan, entro otros. 

Al final los grupos dan a entender que estan categorizados respecto al costo, el revenue y el éxito que estás películas han tenido debido a sus actores y/o directores. 